import requests
from lxml import etree
import os
import concurrent.futures
from tqdm import tqdm
import time
import random

# éšæœºé€‰æ‹©è¯·æ±‚å¤´
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.128 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
]

REFERERS = [
    "https://www.ddyucshu.cc/",
    "https://www.baidu.com/",
    "https://www.google.com/",
    "https://www.bing.com/"
]

# è¯·æ±‚å¤´éšæœºé€‰æ‹©
def get_random_headers():
    return {
        "User-Agent": random.choice(USER_AGENTS),
        "Referer": random.choice(REFERERS),
        "Accept-Language": "en-US,en;q=0.9",
        "Connection": "keep-alive"
    }

BASE_URL = "https://m.ddyucshu.cc/"

# è¾“å…¥å°è¯´IDè·å–ç« èŠ‚åˆ—è¡¨**
def get_chapters(novel_id):
    url = f"{BASE_URL}{novel_id}"
    headers = get_random_headers()
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚ç« èŠ‚ç›®å½•å¤±è´¥: {e}")
        return []

    html = etree.HTML(response.text)

    dt_elements = html.xpath('//dt[contains(text(), "æ­£æ–‡")]')
    if not dt_elements:
        raise ValueError("æœªæ‰¾åˆ°åŒ…å«'æ­£æ–‡'çš„ç« èŠ‚åˆ—è¡¨")

    # è·å–æ‰€æœ‰ç« èŠ‚é“¾æ¥
    chapter_list = []
    for dt in dt_elements:
        links = dt.xpath('./following-sibling::dd/a')
        for link in links:
            chapter_title = link.text.strip()
            chapter_url = link.get("href")
            if not chapter_url.startswith("http"):
                chapter_url = BASE_URL + chapter_url.lstrip("/")
            chapter_list.append((chapter_title, chapter_url))

    return chapter_list

#çˆ¬å–å•ä¸ªç« èŠ‚
def download_chapter(chapter):
    chapter_title, chapter_url = chapter
    retries = 3  # é‡è¯•æ¬¡æ•°
    for _ in range(retries):
        try:
            headers = get_random_headers()
            response = requests.get(chapter_url, headers=headers, timeout=10)
            response.raise_for_status()
            html = etree.HTML(response.text)

            content_div = html.xpath('//div[@id="content"]')[0]
            
            # å¤„ç†<br/>æ ‡ç­¾æ›¿æ¢æˆæ¢è¡Œç¬¦
            content_html = etree.tostring(content_div, encoding='unicode')
            content_text = content_html.replace('<br />', '\n')

            # ç§»é™¤å…¶ä»–æ ‡ç­¾
            content_text = ' '.join(etree.HTML(content_text).xpath('//text()')).replace(' \n', '\n')

            if not content_text:
                print(f"âŒ ç« èŠ‚ `{chapter_title}` æ­£æ–‡æå–å¤±è´¥ï¼")
                return chapter_title, None

            return chapter_title, content_text
        
        except requests.exceptions.RequestException as e:
            print(f"âŒ ä¸‹è½½ç« èŠ‚ `{chapter_title}` å¤±è´¥: {e}")
            time.sleep(random.randint(5, 10))  # å¢åŠ å»¶è¿Ÿï¼ˆ5-10ç§’ï¼‰å†é‡è¯•

    return chapter_title, None

#è¿è¡Œä¸»ç¨‹åº
def main():
    while True:
        print("\n* è¾“å…¥ä¸‹é¢çš„æ•°å­—è¿›å…¥å…¶ä»–åŠŸèƒ½ *")
        print("1. ç›´æ¥è¾“å…¥IDï¼ˆä¾‹å¦‚ç½‘å€https://m.ddyucshu.cc/wapbook/20221439.htmlä¸­åªéœ€è¦è¾“å…¥â€œ20221439â€å³å¯")
        print("2. èµåŠ©æˆ‘ä»¬")
        print("3. é€€å‡º")

        choice = input("è¯·è¾“å…¥é€‰é¡¹: ")
        if choice == "1":
            novel_id = input("è¯·è¾“å…¥å°è¯´ ID: ").strip()
            try:
                chapters = get_chapters(novel_id)
                if not chapters:
                    print("âŒ è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥ï¼Œè¯·é‡è¯•ï¼")
                    continue

                novel_name = novel_id + ".txt"
                print(f"\nğŸ“– å‘ç° {len(chapters)} ç« ï¼Œå¼€å§‹ä¸‹è½½...")

                # **å¤šçº¿ç¨‹åŠ é€Ÿçˆ¬å–**
                with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                    results = list(tqdm(executor.map(download_chapter, chapters), total=len(chapters), desc="ä¸‹è½½è¿›åº¦", unit="ç« "))

                # **ä¿å­˜åˆ°æ–‡ä»¶**
                with open(novel_name, "w", encoding="utf-8") as f:
                    for title, content in results:
                        if content:
                            f.write(f"\n{title}\n{'=' * 40}\n{content}\n")

                print(f"\nâœ… å°è¯´ã€Š{novel_id}ã€‹ä¸‹è½½å®Œæˆï¼Œä¿å­˜åœ¨ {novel_name}")
            
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")

        elif choice == "2":
            print("\næ„Ÿè°¢ä½ çš„æ”¯æŒï¼ä¸è¿‡èµåŠ©å°±å®åœ¨ä¸ç”¨äº†å“ˆã€‚ã€‚ã€‚ã€‚")

        elif choice == "3":
            print("\nğŸ‘‹ é€€å‡ºç¨‹åºï¼")
            break

        else:
            print("\nâŒ è¯·è¾“å…¥æ­£ç¡®çš„é€‰é¡¹ï¼")

if __name__ == "__main__":
    main()